version: '3.3'

######################################################
# COMMONS
######################################################

x-minio-common: &minio-common
  image: docker.io/bitnami/minio:2023
  restart: always
  environment:
    - MINIO_ROOT_USER=minio
    - MINIO_ROOT_PASSWORD=miniosecret
    - MINIO_DISTRIBUTED_MODE_ENABLED=yes
    - MINIO_DISTRIBUTED_NODES=minio,minio2,minio3,minio4
  healthcheck:
    test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
    interval: 30s
    timeout: 20s
    retries: 3
  depends_on: 
    - openldap

x-sparkworker-common: &sparkworker-common
  restart: always
  build: ./docker/spark
  volumes:
    - ./data/spark/work/:/opt/bitnami/spark/work/
    - ./data/spark/logs/:/opt/bitnami/spark/history/
    - ./data/spark/scripts/:/opt/bitnami/spark/scripts/
    - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    - type: bind
      source: ./spark/log4j.properties
      target: /opt/bitnami/spark/conf/log4j.properties
  depends_on:
    - spark-master
  environment:
    - SPARK_MODE=worker
    - SPARK_MASTER="spark://spark-master:7077"
    - SPARK_WORKLOAD=worker
    - SPARK_RPC_AUTHENTICATION_ENABLED=no
    - SPARK_RPC_ENCRYPTION_ENABLED=no
    - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    - SPARK_SSL_ENABLED=no
    - SPARK_USER=spark   

services:
######################################################
# DATABASE SERVICE
######################################################
  mssql:
    restart: always
    image: mcr.microsoft.com/mssql/server:2022-latest
    container_name: mssql
    networks:
      etl-net:
        ipv4_address: 10.5.0.100
    ports:
      - 1401:1433
    volumes:
      - ./mnt/mssql/data/:/var/opt/mssql/data
      - ./mnt/mssql/log/:/var/opt/mssql/log
      - ./mnt/mssql/secrets/:/var/opt/mssql/secrets
      - ./mnt/mssql/backup/:/var/opt/mssql/backup
    environment:
      - ACCEPT_EULA=Y
      - MSSQL_SA_PASSWORD="TradeAtlas*"

  postgres:
    build: './docker/postgres'
    container_name: postgres
    restart: always
    ports:
      - 5401:5432
    networks:
      etl-net:
        ipv4_address: 10.5.0.101
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "postgres", "-U", "postgres" ]
      timeout: 45s
      interval: 10s
      retries: 10
      
  redis:
    image: docker.io/bitnami/redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/bitnami/redis
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      etl-net:
        ipv4_address: 10.5.0.102

######################################################
# LDAP SERVICE
######################################################
  openldap:
    image: docker.io/bitnami/openldap:2.6
    container_name: openldap
    ports:
      - 389:389
      - 636:636
    environment:
      - LDAP_ROOT=dc=tradeatlas,dc=com
      - LDAP_PORT_NUMBER=389
      - LDAP_LDAPS_PORT_NUMBER=636
      - LDAP_ORGANISATION=tradeatlas
      - LDAP_DOMAIN=tradeatlas.com
      - LDAP_ADMIN_DN=cn=admin,dc=tradeatlas,dc=com
      - LDAP_ADMIN_USERNAME=admin
      - LDAP_ADMIN_PASSWORD=admin
      - LDAP_CONFIG_USERNAME=admin
      - LDAP_CONFIG_PASSWORD=admin
      - LDAP_REMOVE_CONFIG_AFTER_SETUP=true
      - LDAP_TLS_VERIFY_CLIENT=never
    volumes:
      - 'openldap_data:/bitnami/openldap'
    networks:
      etl-net:
        ipv4_address: 10.5.0.103

  phpldapadmin:
    image: osixia/phpldapadmin
    container_name: phpldapadmin
    hostname: phpldapadmin
    ports:
      - 18080:80
    environment:
      - PHPLDAPADMIN_LDAP_HOSTS=10.5.0.103
      - PHPLDAPADMIN_HTTPS=false
    depends_on: 
      - openldap
    networks:
      - etl-net

######################################################
# MINIO SERVICE
######################################################
  minio:
    <<: *minio-common
    container_name: minio
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - 'minio_data:/bitnami/minio/data'
    networks:
      etl-net:
        ipv4_address: 10.5.0.104

  minio2:
    <<: *minio-common
    container_name: minio2
    volumes:
      - 'minio_2_data:/bitnami/minio/data'
    networks:
      etl-net: 

  minio3:
    <<: *minio-common
    container_name: minio3
    volumes:
      - 'minio_3_data:/bitnami/minio/data'
    networks:
      etl-net:

  minio4:
    <<: *minio-common
    container_name: minio4
    volumes:
      - 'minio_4_data:/bitnami/minio/data'
    networks:
      etl-net:

  minio-client:
    image: docker.io/bitnami/minio-client:2023
    user: root
    depends_on:
      - minio
      - minio2
      - minio3
      - minio4
    container_name: minio-client
    networks:
      etl-net:
    environment:
      - MINIO_SERVER_HOST="minio"
      - MINIO_SERVER_ACCESS_KEY="minio"
      - MINIO_SERVER_SECRET_KEY="miniosecret"
    entrypoint: >
      /bin/sh -c "
      mc alias set minio http://minio:9000 minio miniosecret;
      mc mb minio/spark-logs;
      mc mb minio/tmp;
      mc mb minio/airflow-logs;
      mc admin user add minio airflow airflow_secret;
      echo 'Added user airflow.';
      mc admin policy set minio readwrite user=airflow;
      exit 0;
      "

######################################################
# HADOOP SERVICES
######################################################
  namenode:
    build: ./docker/hadoop/hadoop-namenode
    restart: always
    container_name: namenode
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    ports:
      - "9870:9870"
    volumes:
      - ./mnt/hadoop/namenode:/hadoop/dfs/name
    networks:
      - etl-net
    environment:
      - CLUSTER_NAME=hadoop_cluster
    healthcheck:
      test: [ "CMD", "nc", "-z", "namenode", "9870" ]
      timeout: 45s
      interval: 10s
      retries: 10

  datanode:
    build: ./docker/hadoop/hadoop-datanode
    restart: always
    container_name: datanode
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - namenode
    volumes:
      - ./mnt/hadoop/datanode:/hadoop/dfs/data
    networks:
      - etl-net
    environment:
      - SERVICE_PRECONDITION=namenode:9870
    healthcheck:
      test: [ "CMD", "nc", "-z", "datanode", "9864" ]
      timeout: 45s
      interval: 10s
      retries: 10

  hive-metastore:
    build: ./docker/hive/hive-metastore
    restart: always
    container_name: hive-metastore
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - namenode
      - datanode
      - postgres
    networks:
      etl-net:
        ipv4_address: 10.5.0.105
    environment:
      - SERVICE_PRECONDITION=namenode:9870 datanode:9864 postgres:5432
    ports:
      - "9083:9083"
    healthcheck:
      test: [ "CMD", "nc", "-z", "hive-metastore", "9083" ]
      timeout: 45s
      interval: 10s
      retries: 10

  hive-server:
    build: ./docker/hive/hive-server
    restart: always
    container_name: hive-server
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - hive-metastore
    networks:
      etl-net:
        ipv4_address: 10.5.0.106
    environment:
      - SERVICE_PRECONDITION=10.5.0.105:9083
    ports:
      - "10000:10000"
      - "10002:10002"
    healthcheck:
      test: [ "CMD", "nc", "-z", "hive-server", "10002" ]
      timeout: 45s
      interval: 10s
      retries: 10

  hive-webhcat:
    build: ./docker/hive/hive-webhcat
    restart: always
    container_name: hive-webhcat
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - hive-server
    networks:
      - etl-net
    environment:
      - SERVICE_PRECONDITION=10.5.0.106:10000
    healthcheck:
      test: [ "CMD", "nc", "-z", "hive-webhcat", "50111" ]
      timeout: 45s
      interval: 10s
      retries: 10

  hue:
    build: ./docker/hue
    restart: always
    container_name: hue
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - hive-server
      - postgres
    ports:
      - "8888:8888"
    networks:
      - etl-net
    volumes:
      - ./mnt/hue/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    environment:
      - SERVICE_PRECONDITION=10.5.0.106:10000 postgres:5432
    healthcheck:
      test: [ "CMD", "nc", "-z", "hue", "8888" ]
      timeout: 45s
      interval: 10s
      retries: 10

######################################################
# SPARK SERVICE
######################################################
  spark-master:
    build: ./docker/spark/spark-master
    restart: always
    container_name: spark-master
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    ports:
      - "4040:4040"
      - "7077:7077"
    networks:
      - etl-net
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-master", "4040" ]
      timeout: 45s
      interval: 10s
      retries: 10

  spark-worker-1:
    build: ./docker/spark/spark-worker
    container_name: spark-worker-1
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    networks:
      - etl-net
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-worker-1", "8081" ]
      timeout: 45s
      interval: 10s
      retries: 10


  spark-worker-2:
    build: ./docker/spark/spark-worker
    container_name: spark-worker-2
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    networks:
      - etl-net
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-worker-2", "8081" ]
      timeout: 45s
      interval: 10s
      retries: 10


  spark-worker-3:
    build: ./docker/spark/spark-worker
    container_name: spark-worker-3
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    networks:
      - etl-net
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-worker-3", "8081" ]
      timeout: 45s
      interval: 10s
      retries: 10


  spark-worker-4:
    build: ./docker/spark/spark-worker
    container_name: spark-worker-4
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - spark-master
    ports:
      - "8084:8081"
    networks:
      - etl-net
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-worker-4", "8081" ]
      timeout: 45s
      interval: 10s
      retries: 10
    
  livy:
    build: ./docker/livy
    container_name: livy
    restart: always
    command: ["sh", "-c", "/opt/bitnami/livy/bin/livy-server"]
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    volumes:
      - type: bind
        source: ./docker/livy/conf/
        target: /opt/bitnami/livy/conf/
      - type: bind
        source: ./docker/livy/target/
        target: /target/
      - type: bind
        source: ./docker/livy/data/
        target: /data/
    ports:
      - '8998:8998'
    networks:
      - etl-net
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3
      - spark-worker-4


######################################################
# AIRFLOW
######################################################

  airflow:
    build: ./docker/airflow
    restart: always
    container_name: airflow
    volumes:
      - ./mnt/airflow/airflow.cfg:/opt/airflow/airflow.cfg
      - ./mnt/airflow/dags:/opt/airflow/dags
      - ./mnt/airflow/logs:/opt/airflow/logs
    ports:
      - 8080:8080
    networks:
      - etl-net
    healthcheck:
      test: [ "CMD", "nc", "-z", "airflow", "8080" ]
      timeout: 45s
      interval: 10s
      retries: 10

######################################################
# NETWORKS
######################################################
networks:
  etl-net:
    name: etlnet
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: "10.5.0.1"
    driver: bridge

######################################################
# VOLUMES
######################################################
volumes:
  minio_data:
    driver: local
  minio_2_data:
    driver: local
  minio_3_data:
    driver: local
  minio_4_data:
    driver: local
  openldap_data:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local